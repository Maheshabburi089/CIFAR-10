{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-11T14:57:14.937120Z","iopub.status.busy":"2022-12-11T14:57:14.936610Z","iopub.status.idle":"2022-12-11T14:57:30.714894Z","shell.execute_reply":"2022-12-11T14:57:30.713796Z","shell.execute_reply.started":"2022-12-11T14:57:14.937035Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n"]}],"source":["import pickle\n","\n","import matplotlib.pyplot as plt\n","from keras.datasets import cifar10\n","from keras.layers import (Activation, BatchNormalization, Conv2D, Dense,\n","                          Dropout, Flatten, Input, MaxPool2D)\n","from keras.models import Model\n","from keras.optimizers import adam_v2 \n","from keras.preprocessing.image import ImageDataGenerator\n","# import categorical from keras.utils\n","from tensorflow.keras.utils import to_categorical\n","\n","(X_train, y_train), (X_val, y_val) = cifar10.load_data()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T15:06:13.954534Z","iopub.status.busy":"2022-12-11T15:06:13.953791Z","iopub.status.idle":"2022-12-11T15:06:13.971334Z","shell.execute_reply":"2022-12-11T15:06:13.970023Z","shell.execute_reply.started":"2022-12-11T15:06:13.954498Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 1771379730218654834\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14459600896\n","locality {\n","  bus_id: 1\n","  links {\n","    link {\n","      device_id: 1\n","      type: \"StreamExecutor\"\n","      strength: 1\n","    }\n","  }\n","}\n","incarnation: 11002691317650100347\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",", name: \"/device:GPU:1\"\n","device_type: \"GPU\"\n","memory_limit: 14459600896\n","locality {\n","  bus_id: 1\n","  links {\n","    link {\n","      type: \"StreamExecutor\"\n","      strength: 1\n","    }\n","  }\n","}\n","incarnation: 10386191716618638842\n","physical_device_desc: \"device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\"\n","]\n"]},{"name":"stderr","output_type":"stream","text":["2022-12-11 15:06:13.956228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.956851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.957743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.958175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.958849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.959245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.960110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.960549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.961289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.961651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","2022-12-11 15:06:13.961758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 15:06:13.962392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"]}],"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T14:57:30.717653Z","iopub.status.busy":"2022-12-11T14:57:30.716897Z","iopub.status.idle":"2022-12-11T14:57:30.729469Z","shell.execute_reply":"2022-12-11T14:57:30.727702Z","shell.execute_reply.started":"2022-12-11T14:57:30.717611Z"},"trusted":true},"outputs":[],"source":["y_train = to_categorical(y_train)\n","y_val = to_categorical(y_val)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T14:57:30.731215Z","iopub.status.busy":"2022-12-11T14:57:30.730750Z","iopub.status.idle":"2022-12-11T14:57:36.917370Z","shell.execute_reply":"2022-12-11T14:57:36.916197Z","shell.execute_reply.started":"2022-12-11T14:57:30.731178Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-11 14:57:31.050069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.050984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.380855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.381787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.382631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.383418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.385011: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-11 14:57:31.628264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.629229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.630063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.630797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.631509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:31.632254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:36.159479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:36.160490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:36.161205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:36.161943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:36.162737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:36.163394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","2022-12-11 14:57:36.168088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-11 14:57:36.168783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"]}],"source":["input = Input(shape=(32, 32, 3))\n","X = Conv2D(64, (1, 1))(input)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Conv2D(64, (3, 3))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Conv2D(64, (5, 5))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Dropout(0.25)(X)\n","X = MaxPool2D((2,2))(X)\n","\n","X = Conv2D(128, (1, 1))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Conv2D(128, (3, 3))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Conv2D(128, (5, 5))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Dropout(0.25)(X)\n","X = Conv2D(256, (1, 1))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Conv2D(256, (3, 3))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Conv2D(256, (5, 5))(X)\n","X = BatchNormalization()(X)\n","X = Activation(\"relu\")(X)\n","X = Dropout(0.25)(X)\n","X = Flatten()(X)\n","output = Dense(10, activation=\"softmax\")(X)\n","\n","model = Model(input, output)\n","\n","optimizer = adam_v2.Adam(learning_rate=0.001)\n","\n","model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T14:57:58.399630Z","iopub.status.busy":"2022-12-11T14:57:58.398893Z","iopub.status.idle":"2022-12-11T14:57:58.926655Z","shell.execute_reply":"2022-12-11T14:57:58.925343Z","shell.execute_reply.started":"2022-12-11T14:57:58.399593Z"},"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    channel_shift_range=50,\n","    horizontal_flip=True)\n","validationgen = ImageDataGenerator(\n","    rescale=1./255)\n","\n","\n","datagen.fit(X_train)\n","validationgen.fit(X_val)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T15:06:33.795432Z","iopub.status.busy":"2022-12-11T15:06:33.794821Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/700\n","390/390 [==============================] - 47s 119ms/step - loss: 1.2865 - accuracy: 0.5401 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 2/700\n","390/390 [==============================] - 48s 122ms/step - loss: 1.1440 - accuracy: 0.5924 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 3/700\n","390/390 [==============================] - 47s 119ms/step - loss: 1.0521 - accuracy: 0.6293 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 4/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.9690 - accuracy: 0.6598 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 5/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.9168 - accuracy: 0.6801 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 6/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.8708 - accuracy: 0.6968 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 7/700\n","390/390 [==============================] - 48s 123ms/step - loss: 0.8314 - accuracy: 0.7107 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 8/700\n","390/390 [==============================] - 47s 121ms/step - loss: 0.7950 - accuracy: 0.7233 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 9/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.7662 - accuracy: 0.7351 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 10/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.7422 - accuracy: 0.7433 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 11/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.7102 - accuracy: 0.7527 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 12/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.6968 - accuracy: 0.7604 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 13/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.6771 - accuracy: 0.7657 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 14/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.6539 - accuracy: 0.7735 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 15/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.6430 - accuracy: 0.7755 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 16/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.6258 - accuracy: 0.7830 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 17/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.6149 - accuracy: 0.7875 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 18/700\n","390/390 [==============================] - 47s 119ms/step - loss: 0.6031 - accuracy: 0.7927 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 19/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.5900 - accuracy: 0.7955 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 20/700\n","390/390 [==============================] - 47s 119ms/step - loss: 0.5704 - accuracy: 0.8019 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 21/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.5606 - accuracy: 0.8048 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 22/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.5536 - accuracy: 0.8092 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 23/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.5433 - accuracy: 0.8126 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 24/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.5384 - accuracy: 0.8129 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 25/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.5269 - accuracy: 0.8183 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 26/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.5223 - accuracy: 0.8201 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 27/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.5159 - accuracy: 0.8225 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 28/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4957 - accuracy: 0.8265 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 29/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.4959 - accuracy: 0.8271 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 30/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4947 - accuracy: 0.8270 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 31/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.4819 - accuracy: 0.8348 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 32/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4807 - accuracy: 0.8333 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 33/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.4706 - accuracy: 0.8369 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 34/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4706 - accuracy: 0.8359 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 35/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.4561 - accuracy: 0.8417 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 36/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.4502 - accuracy: 0.8435 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 37/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4536 - accuracy: 0.8433 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 38/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.4434 - accuracy: 0.8474 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 39/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.4413 - accuracy: 0.8470 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 40/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.4371 - accuracy: 0.8484 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 41/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.4308 - accuracy: 0.8497 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 42/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.4287 - accuracy: 0.8510 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 43/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4200 - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 44/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4213 - accuracy: 0.8550 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 45/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.4138 - accuracy: 0.8566 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 46/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.4062 - accuracy: 0.8591 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 47/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.4105 - accuracy: 0.8573 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 48/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.4032 - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 49/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.4002 - accuracy: 0.8621 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 50/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3932 - accuracy: 0.8634 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 51/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3908 - accuracy: 0.8646 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 52/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3869 - accuracy: 0.8660 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 53/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3879 - accuracy: 0.8660 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 54/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3806 - accuracy: 0.8680 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 55/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.3774 - accuracy: 0.8685 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 56/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.3789 - accuracy: 0.8680 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 57/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3749 - accuracy: 0.8692 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 58/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.3685 - accuracy: 0.8715 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 59/700\n","390/390 [==============================] - 46s 116ms/step - loss: 0.3559 - accuracy: 0.8753 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 60/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3672 - accuracy: 0.8722 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 61/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3618 - accuracy: 0.8747 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 62/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3592 - accuracy: 0.8759 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 63/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3533 - accuracy: 0.8767 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 64/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3592 - accuracy: 0.8759 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 65/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3503 - accuracy: 0.8778 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 66/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3479 - accuracy: 0.8790 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 67/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3464 - accuracy: 0.8786 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 68/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3465 - accuracy: 0.8789 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 69/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.3400 - accuracy: 0.8826 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 70/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3377 - accuracy: 0.8833 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 71/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.3405 - accuracy: 0.8825 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 72/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3381 - accuracy: 0.8826 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 73/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3339 - accuracy: 0.8837 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 74/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3358 - accuracy: 0.8838 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 75/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.3268 - accuracy: 0.8856 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 76/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3309 - accuracy: 0.8836 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 77/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3325 - accuracy: 0.8855 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 78/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.3235 - accuracy: 0.8881 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 79/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3213 - accuracy: 0.8882 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 80/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.3188 - accuracy: 0.8880 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 81/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3154 - accuracy: 0.8892 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 82/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.3198 - accuracy: 0.8889 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 83/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.3200 - accuracy: 0.8895 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 84/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.3156 - accuracy: 0.8905 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 85/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3124 - accuracy: 0.8907 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 86/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.3092 - accuracy: 0.8921 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 87/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3053 - accuracy: 0.8922 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 88/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.3085 - accuracy: 0.8925 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 89/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3036 - accuracy: 0.8938 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 90/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.3017 - accuracy: 0.8935 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 91/700\n","390/390 [==============================] - 46s 116ms/step - loss: 0.3022 - accuracy: 0.8938 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 92/700\n","390/390 [==============================] - 47s 119ms/step - loss: 0.3053 - accuracy: 0.8932 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 93/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2952 - accuracy: 0.8962 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 94/700\n","390/390 [==============================] - 47s 119ms/step - loss: 0.2981 - accuracy: 0.8962 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 95/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2918 - accuracy: 0.8981 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 96/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2953 - accuracy: 0.8964 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 97/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2923 - accuracy: 0.8982 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 98/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.2900 - accuracy: 0.8972 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 99/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2862 - accuracy: 0.9009 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 100/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2883 - accuracy: 0.8987 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 101/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2869 - accuracy: 0.9003 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 102/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2869 - accuracy: 0.8999 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 103/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2816 - accuracy: 0.9010 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 104/700\n","390/390 [==============================] - 46s 116ms/step - loss: 0.2821 - accuracy: 0.9001 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 105/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2759 - accuracy: 0.9034 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 106/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2807 - accuracy: 0.9026 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 107/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2789 - accuracy: 0.9028 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 108/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2811 - accuracy: 0.9013 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 109/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2776 - accuracy: 0.9035 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 110/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2798 - accuracy: 0.9017 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 111/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2771 - accuracy: 0.9038 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 112/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2658 - accuracy: 0.9061 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 113/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2720 - accuracy: 0.9058 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 114/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2698 - accuracy: 0.9061 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 115/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2695 - accuracy: 0.9062 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 116/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2663 - accuracy: 0.9073 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 117/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2756 - accuracy: 0.9028 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 118/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2647 - accuracy: 0.9072 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 119/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2667 - accuracy: 0.9072 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 120/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2674 - accuracy: 0.9066 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 121/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2592 - accuracy: 0.9092 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 122/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2575 - accuracy: 0.9093 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 123/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2587 - accuracy: 0.9082 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 124/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2564 - accuracy: 0.9081 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 125/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2591 - accuracy: 0.9092 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 126/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2560 - accuracy: 0.9096 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 127/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2560 - accuracy: 0.9109 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 128/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2551 - accuracy: 0.9106 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 129/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2565 - accuracy: 0.9105 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 130/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2556 - accuracy: 0.9110 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 131/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2502 - accuracy: 0.9119 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 132/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2554 - accuracy: 0.9106 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 133/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2473 - accuracy: 0.9128 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 134/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2486 - accuracy: 0.9139 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 135/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2496 - accuracy: 0.9128 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 136/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2473 - accuracy: 0.9126 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 137/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.2487 - accuracy: 0.9133 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 138/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2473 - accuracy: 0.9131 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 139/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2476 - accuracy: 0.9129 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 140/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2450 - accuracy: 0.9142 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 141/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2399 - accuracy: 0.9159 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 142/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2422 - accuracy: 0.9152 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 143/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2405 - accuracy: 0.9154 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 144/700\n","390/390 [==============================] - 47s 119ms/step - loss: 0.2418 - accuracy: 0.9159 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 145/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2393 - accuracy: 0.9175 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 146/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.2364 - accuracy: 0.9173 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 147/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2372 - accuracy: 0.9166 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 148/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.2367 - accuracy: 0.9175 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 149/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2359 - accuracy: 0.9171 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 150/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2371 - accuracy: 0.9165 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 151/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2397 - accuracy: 0.9155 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 152/700\n","390/390 [==============================] - 47s 120ms/step - loss: 0.2401 - accuracy: 0.9176 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 153/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2301 - accuracy: 0.9190 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 154/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.2345 - accuracy: 0.9182 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 155/700\n","390/390 [==============================] - 46s 116ms/step - loss: 0.2301 - accuracy: 0.9183 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 156/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2360 - accuracy: 0.9183 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 157/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2317 - accuracy: 0.9190 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 158/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2308 - accuracy: 0.9184 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 159/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2375 - accuracy: 0.9171 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 160/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2278 - accuracy: 0.9195 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 161/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.2258 - accuracy: 0.9212 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 162/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2280 - accuracy: 0.9199 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 163/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2289 - accuracy: 0.9201 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 164/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2249 - accuracy: 0.9213 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 165/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2288 - accuracy: 0.9212 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 166/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2251 - accuracy: 0.9218 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 167/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2215 - accuracy: 0.9218 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 168/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.2224 - accuracy: 0.9218 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 169/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2236 - accuracy: 0.9225 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 170/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2206 - accuracy: 0.9227 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 171/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2264 - accuracy: 0.9201 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 172/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2169 - accuracy: 0.9224 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 173/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2224 - accuracy: 0.9225 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 174/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2216 - accuracy: 0.9228 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 175/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2164 - accuracy: 0.9240 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 176/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2162 - accuracy: 0.9243 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 177/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2172 - accuracy: 0.9258 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 178/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2162 - accuracy: 0.9235 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 179/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2176 - accuracy: 0.9226 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 180/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2115 - accuracy: 0.9252 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 181/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2190 - accuracy: 0.9218 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 182/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2157 - accuracy: 0.9244 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 183/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2161 - accuracy: 0.9239 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 184/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.2139 - accuracy: 0.9259 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 185/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.2105 - accuracy: 0.9269 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 186/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2107 - accuracy: 0.9253 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 187/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.2136 - accuracy: 0.9257 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 188/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2136 - accuracy: 0.9258 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 189/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2124 - accuracy: 0.9251 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 190/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.2107 - accuracy: 0.9248 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 191/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2072 - accuracy: 0.9272 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 192/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2095 - accuracy: 0.9265 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 193/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2055 - accuracy: 0.9280 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 194/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2050 - accuracy: 0.9280 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 195/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2048 - accuracy: 0.9267 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 196/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2081 - accuracy: 0.9268 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 197/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2060 - accuracy: 0.9282 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 198/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2041 - accuracy: 0.9289 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 199/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2050 - accuracy: 0.9286 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 200/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2095 - accuracy: 0.9278 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 201/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.2074 - accuracy: 0.9269 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 202/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2029 - accuracy: 0.9296 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 203/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2033 - accuracy: 0.9296 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 204/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2069 - accuracy: 0.9278 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 205/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2015 - accuracy: 0.9302 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 206/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2030 - accuracy: 0.9294 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 207/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2027 - accuracy: 0.9283 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 208/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.2018 - accuracy: 0.9276 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 209/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2004 - accuracy: 0.9295 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 210/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.2024 - accuracy: 0.9298 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 211/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1974 - accuracy: 0.9308 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 212/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1972 - accuracy: 0.9323 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 213/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.2049 - accuracy: 0.9292 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 214/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1997 - accuracy: 0.9306 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 215/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.2002 - accuracy: 0.9288 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 216/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1998 - accuracy: 0.9301 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 217/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1970 - accuracy: 0.9314 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 218/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1972 - accuracy: 0.9316 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 219/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1955 - accuracy: 0.9314 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 220/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1966 - accuracy: 0.9311 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 221/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1928 - accuracy: 0.9320 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 222/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.1965 - accuracy: 0.9321 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 223/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1928 - accuracy: 0.9323 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 224/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.2017 - accuracy: 0.9300 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 225/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1934 - accuracy: 0.9315 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 226/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1900 - accuracy: 0.9348 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 227/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1925 - accuracy: 0.9329 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 228/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1923 - accuracy: 0.9339 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 229/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1942 - accuracy: 0.9308 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 230/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1849 - accuracy: 0.9358 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 231/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1889 - accuracy: 0.9331 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 232/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1907 - accuracy: 0.9333 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 233/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1880 - accuracy: 0.9348 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 234/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1886 - accuracy: 0.9337 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 235/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1882 - accuracy: 0.9344 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 236/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1880 - accuracy: 0.9359 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 237/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1893 - accuracy: 0.9332 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 238/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1883 - accuracy: 0.9352 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 239/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1864 - accuracy: 0.9352 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 240/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1841 - accuracy: 0.9352 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 241/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1863 - accuracy: 0.9336 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 242/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1864 - accuracy: 0.9342 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 243/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1835 - accuracy: 0.9361 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 244/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1848 - accuracy: 0.9345 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 245/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1820 - accuracy: 0.9355 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 246/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1829 - accuracy: 0.9363 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 247/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1872 - accuracy: 0.9346 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 248/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1843 - accuracy: 0.9350 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 249/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1852 - accuracy: 0.9347 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 250/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1834 - accuracy: 0.9361 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 251/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1809 - accuracy: 0.9373 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 252/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1814 - accuracy: 0.9370 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 253/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1823 - accuracy: 0.9358 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 254/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1816 - accuracy: 0.9362 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 255/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1796 - accuracy: 0.9368 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 256/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1774 - accuracy: 0.9368 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 257/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1807 - accuracy: 0.9370 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 258/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1836 - accuracy: 0.9369 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 259/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1796 - accuracy: 0.9378 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 260/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1773 - accuracy: 0.9377 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 261/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1766 - accuracy: 0.9378 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 262/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1733 - accuracy: 0.9394 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 263/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1811 - accuracy: 0.9361 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 264/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1785 - accuracy: 0.9371 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 265/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1786 - accuracy: 0.9373 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 266/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1747 - accuracy: 0.9387 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 267/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1776 - accuracy: 0.9379 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 268/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1752 - accuracy: 0.9389 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 269/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1776 - accuracy: 0.9381 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 270/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1785 - accuracy: 0.9382 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 271/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1760 - accuracy: 0.9376 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 272/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1717 - accuracy: 0.9402 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 273/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1713 - accuracy: 0.9415 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 274/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1765 - accuracy: 0.9381 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 275/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1731 - accuracy: 0.9389 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 276/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1753 - accuracy: 0.9387 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 277/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1717 - accuracy: 0.9407 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 278/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1749 - accuracy: 0.9381 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 279/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1732 - accuracy: 0.9397 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 280/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.1717 - accuracy: 0.9399 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 281/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1716 - accuracy: 0.9412 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 282/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1759 - accuracy: 0.9385 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 283/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1697 - accuracy: 0.9399 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 284/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1668 - accuracy: 0.9412 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 285/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1682 - accuracy: 0.9408 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 286/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1725 - accuracy: 0.9407 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 287/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1648 - accuracy: 0.9409 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 288/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1739 - accuracy: 0.9385 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 289/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1694 - accuracy: 0.9406 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 290/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1720 - accuracy: 0.9404 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 291/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1651 - accuracy: 0.9422 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 292/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.1718 - accuracy: 0.9405 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 293/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1646 - accuracy: 0.9416 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 294/700\n","390/390 [==============================] - 46s 119ms/step - loss: 0.1692 - accuracy: 0.9415 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 295/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1728 - accuracy: 0.9402 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 296/700\n","390/390 [==============================] - 46s 117ms/step - loss: 0.1707 - accuracy: 0.9399 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 297/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1671 - accuracy: 0.9414 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 298/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1711 - accuracy: 0.9403 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 299/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1671 - accuracy: 0.9412 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 300/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1631 - accuracy: 0.9434 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 301/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1691 - accuracy: 0.9415 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 302/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1639 - accuracy: 0.9426 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 303/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1683 - accuracy: 0.9408 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 304/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1687 - accuracy: 0.9407 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 305/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1640 - accuracy: 0.9428 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 306/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1647 - accuracy: 0.9426 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 307/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1613 - accuracy: 0.9436 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 308/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1632 - accuracy: 0.9424 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 309/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1684 - accuracy: 0.9409 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 310/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1648 - accuracy: 0.9424 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 311/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1620 - accuracy: 0.9427 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 312/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1635 - accuracy: 0.9425 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 313/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1645 - accuracy: 0.9414 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 314/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1615 - accuracy: 0.9441 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 315/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1628 - accuracy: 0.9425 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 316/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1633 - accuracy: 0.9441 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 317/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1640 - accuracy: 0.9428 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 318/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1567 - accuracy: 0.9446 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 319/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1618 - accuracy: 0.9433 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 320/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1604 - accuracy: 0.9445 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 321/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1597 - accuracy: 0.9447 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 322/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1610 - accuracy: 0.9439 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 323/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1643 - accuracy: 0.9419 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 324/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1593 - accuracy: 0.9433 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 325/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1599 - accuracy: 0.9446 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 326/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1615 - accuracy: 0.9438 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 327/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1635 - accuracy: 0.9426 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 328/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1589 - accuracy: 0.9441 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 329/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1608 - accuracy: 0.9440 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 330/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1600 - accuracy: 0.9442 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 331/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1603 - accuracy: 0.9447 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 332/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1618 - accuracy: 0.9439 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 333/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1554 - accuracy: 0.9461 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 334/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1568 - accuracy: 0.9458 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 335/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1594 - accuracy: 0.9447 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 336/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1573 - accuracy: 0.9447 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 337/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1562 - accuracy: 0.9449 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 338/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1569 - accuracy: 0.9447 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 339/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1555 - accuracy: 0.9461 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 340/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1568 - accuracy: 0.9460 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 341/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1517 - accuracy: 0.9472 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 342/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1520 - accuracy: 0.9469 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 343/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1629 - accuracy: 0.9428 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 344/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1545 - accuracy: 0.9466 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 345/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1583 - accuracy: 0.9449 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 346/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1523 - accuracy: 0.9470 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 347/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1551 - accuracy: 0.9463 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 348/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1586 - accuracy: 0.9436 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 349/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1539 - accuracy: 0.9456 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 350/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1544 - accuracy: 0.9461 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 351/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1559 - accuracy: 0.9457 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 352/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1565 - accuracy: 0.9447 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 353/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1493 - accuracy: 0.9475 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 354/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1531 - accuracy: 0.9470 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 355/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1521 - accuracy: 0.9466 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 356/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1538 - accuracy: 0.9464 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 357/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1516 - accuracy: 0.9468 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 358/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1551 - accuracy: 0.9456 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 359/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1511 - accuracy: 0.9464 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 360/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1510 - accuracy: 0.9475 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 361/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1495 - accuracy: 0.9478 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 362/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1519 - accuracy: 0.9470 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 363/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1546 - accuracy: 0.9472 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 364/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1489 - accuracy: 0.9484 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 365/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1508 - accuracy: 0.9471 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 366/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1533 - accuracy: 0.9466 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 367/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1523 - accuracy: 0.9478 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 368/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1504 - accuracy: 0.9487 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 369/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1480 - accuracy: 0.9486 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 370/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1467 - accuracy: 0.9492 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 371/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1524 - accuracy: 0.9468 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 372/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1435 - accuracy: 0.9502 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 373/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1508 - accuracy: 0.9476 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 374/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1423 - accuracy: 0.9495 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 375/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1461 - accuracy: 0.9490 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 376/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1511 - accuracy: 0.9489 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 377/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1490 - accuracy: 0.9481 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 378/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1494 - accuracy: 0.9471 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 379/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1512 - accuracy: 0.9472 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 380/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1470 - accuracy: 0.9489 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 381/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1502 - accuracy: 0.9474 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 382/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1444 - accuracy: 0.9498 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 383/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1472 - accuracy: 0.9478 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 384/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1486 - accuracy: 0.9495 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 385/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1455 - accuracy: 0.9474 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 386/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1451 - accuracy: 0.9487 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 387/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1435 - accuracy: 0.9496 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 388/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1430 - accuracy: 0.9496 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 389/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1485 - accuracy: 0.9483 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 390/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1416 - accuracy: 0.9498 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 391/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1471 - accuracy: 0.9495 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 392/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1452 - accuracy: 0.9492 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 393/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1469 - accuracy: 0.9483 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 394/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1444 - accuracy: 0.9500 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 395/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1420 - accuracy: 0.9492 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 396/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1455 - accuracy: 0.9479 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 397/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1445 - accuracy: 0.9502 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 398/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1454 - accuracy: 0.9484 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 399/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1443 - accuracy: 0.9497 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 400/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1409 - accuracy: 0.9503 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 401/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1460 - accuracy: 0.9494 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 402/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1436 - accuracy: 0.9498 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 403/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1404 - accuracy: 0.9512 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 404/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1437 - accuracy: 0.9502 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 405/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1421 - accuracy: 0.9507 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 406/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1407 - accuracy: 0.9495 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 407/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1439 - accuracy: 0.9496 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 408/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1428 - accuracy: 0.9500 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 409/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1419 - accuracy: 0.9511 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 410/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 411/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1406 - accuracy: 0.9505 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 412/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1384 - accuracy: 0.9516 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 413/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1403 - accuracy: 0.9519 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 414/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1434 - accuracy: 0.9494 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 415/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1406 - accuracy: 0.9514 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 416/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1436 - accuracy: 0.9491 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 417/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1391 - accuracy: 0.9506 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 418/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1345 - accuracy: 0.9533 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 419/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1414 - accuracy: 0.9517 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 420/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1421 - accuracy: 0.9500 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 421/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1423 - accuracy: 0.9505 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 422/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1461 - accuracy: 0.9485 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 423/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1358 - accuracy: 0.9519 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 424/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1403 - accuracy: 0.9519 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 425/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1375 - accuracy: 0.9512 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 426/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1372 - accuracy: 0.9520 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 427/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1379 - accuracy: 0.9520 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 428/700\n"," 81/390 [=====>........................] - ETA: 32s - loss: 0.1310 - accuracy: 0.9565"]},{"name":"stderr","output_type":"stream","text":["IOPub message rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_msg_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]},{"name":"stdout","output_type":"stream","text":["390/390 [==============================] - 44s 111ms/step - loss: 0.1379 - accuracy: 0.9511 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 431/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1400 - accuracy: 0.9504 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 432/700\n","390/390 [==============================] - 46s 118ms/step - loss: 0.1382 - accuracy: 0.9516 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 433/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1422 - accuracy: 0.9506 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 434/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1429 - accuracy: 0.9499 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 435/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1373 - accuracy: 0.9520 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 436/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1375 - accuracy: 0.9522 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 437/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1365 - accuracy: 0.9532 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 438/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1385 - accuracy: 0.9521 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 439/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1347 - accuracy: 0.9527 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 440/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 441/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1385 - accuracy: 0.9519 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 442/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1407 - accuracy: 0.9510 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 443/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1337 - accuracy: 0.9545 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 444/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1391 - accuracy: 0.9513 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 445/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1366 - accuracy: 0.9525 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 446/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1334 - accuracy: 0.9523 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 447/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1363 - accuracy: 0.9534 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 448/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1338 - accuracy: 0.9528 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 449/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1340 - accuracy: 0.9526 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 450/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1342 - accuracy: 0.9532 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 451/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1341 - accuracy: 0.9531 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 452/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1384 - accuracy: 0.9522 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 453/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1336 - accuracy: 0.9543 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 454/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1362 - accuracy: 0.9526 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 455/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1364 - accuracy: 0.9523 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 456/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1284 - accuracy: 0.9548 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 457/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1336 - accuracy: 0.9539 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 458/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1349 - accuracy: 0.9526 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 459/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1345 - accuracy: 0.9539 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 460/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1367 - accuracy: 0.9528 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 461/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1333 - accuracy: 0.9526 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 462/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1347 - accuracy: 0.9536 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 463/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1345 - accuracy: 0.9527 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 466/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1339 - accuracy: 0.9536 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 467/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1301 - accuracy: 0.9544 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 468/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1326 - accuracy: 0.9535 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 469/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1311 - accuracy: 0.9551 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 470/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1312 - accuracy: 0.9541 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 471/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1313 - accuracy: 0.9543 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 472/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1369 - accuracy: 0.9528 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 473/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1331 - accuracy: 0.9534 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 474/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1315 - accuracy: 0.9544 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 475/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1317 - accuracy: 0.9539 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 476/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1269 - accuracy: 0.9551 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 477/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1309 - accuracy: 0.9546 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 478/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1323 - accuracy: 0.9540 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 479/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1319 - accuracy: 0.9551 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 480/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1324 - accuracy: 0.9540 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 481/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1301 - accuracy: 0.9549 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 482/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1305 - accuracy: 0.9555 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 483/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1287 - accuracy: 0.9552 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 484/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1314 - accuracy: 0.9543 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 485/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1308 - accuracy: 0.9541 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 486/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1282 - accuracy: 0.9560 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 487/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1285 - accuracy: 0.9548 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 488/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1289 - accuracy: 0.9549 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 489/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1319 - accuracy: 0.9536 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 490/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1295 - accuracy: 0.9556 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 491/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1282 - accuracy: 0.9560 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 492/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1276 - accuracy: 0.9554 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 493/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1309 - accuracy: 0.9549 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 494/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1279 - accuracy: 0.9558 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 495/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1270 - accuracy: 0.9567 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 496/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1288 - accuracy: 0.9549 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 497/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1282 - accuracy: 0.9545 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 498/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1263 - accuracy: 0.9554 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 499/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1269 - accuracy: 0.9551 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 500/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1318 - accuracy: 0.9529 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 501/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1274 - accuracy: 0.9561 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 502/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1300 - accuracy: 0.9550 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 503/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1258 - accuracy: 0.9562 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 504/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1278 - accuracy: 0.9551 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 505/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1239 - accuracy: 0.9561 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 506/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1298 - accuracy: 0.9546 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 507/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1274 - accuracy: 0.9555 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 508/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1256 - accuracy: 0.9559 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 509/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1292 - accuracy: 0.9544 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 510/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1262 - accuracy: 0.9568 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 511/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1299 - accuracy: 0.9552 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 512/700\n","390/390 [==============================] - 44s 114ms/step - loss: 0.1280 - accuracy: 0.9546 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 513/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1268 - accuracy: 0.9558 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 514/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1267 - accuracy: 0.9559 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 515/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1229 - accuracy: 0.9574 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 516/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1221 - accuracy: 0.9582 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 517/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1287 - accuracy: 0.9548 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 518/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1271 - accuracy: 0.9559 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 519/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1281 - accuracy: 0.9558 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 520/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1283 - accuracy: 0.9544 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 521/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1222 - accuracy: 0.9575 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 522/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1271 - accuracy: 0.9559 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 523/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1288 - accuracy: 0.9562 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 524/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1239 - accuracy: 0.9568 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 525/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1226 - accuracy: 0.9569 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 526/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1273 - accuracy: 0.9570 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 527/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1271 - accuracy: 0.9557 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 528/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1247 - accuracy: 0.9559 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 529/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1256 - accuracy: 0.9570 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 530/700\n","390/390 [==============================] - 45s 116ms/step - loss: 0.1244 - accuracy: 0.9573 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 531/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1201 - accuracy: 0.9578 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 532/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1233 - accuracy: 0.9574 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 533/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1274 - accuracy: 0.9553 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 534/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1233 - accuracy: 0.9560 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 535/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1280 - accuracy: 0.9565 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 536/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1221 - accuracy: 0.9565 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 537/700\n","390/390 [==============================] - 45s 115ms/step - loss: 0.1260 - accuracy: 0.9573 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 538/700\n","390/390 [==============================] - 45s 114ms/step - loss: 0.1196 - accuracy: 0.9570 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 539/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1248 - accuracy: 0.9568 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 540/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1221 - accuracy: 0.9574 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 541/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1277 - accuracy: 0.9559 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 542/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1248 - accuracy: 0.9558 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 543/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1253 - accuracy: 0.9564 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 544/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1191 - accuracy: 0.9580 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 545/700\n","390/390 [==============================] - 44s 113ms/step - loss: 0.1210 - accuracy: 0.9580 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 546/700\n","390/390 [==============================] - 43s 111ms/step - loss: 0.1212 - accuracy: 0.9580 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 547/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1200 - accuracy: 0.9579 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 548/700\n","390/390 [==============================] - 44s 111ms/step - loss: 0.1241 - accuracy: 0.9563 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 549/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1222 - accuracy: 0.9574 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 550/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1183 - accuracy: 0.9584 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 551/700\n","390/390 [==============================] - 44s 112ms/step - loss: 0.1222 - accuracy: 0.9569 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 552/700\n","390/390 [==============================] - 43s 110ms/step - loss: 0.1202 - accuracy: 0.9585 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 553/700\n","  2/390 [..............................] - ETA: 38s - loss: 0.0826 - accuracy: 0.9805"]}],"source":["history = model.fit(datagen.flow(X_train, y_train, batch_size=128),\n","                    steps_per_epoch=len(X_train) / 128, validation_data=validationgen.flow(X_val, y_val), epochs=700).history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"e42b2ccb67b99ad21265aed3e7d615f64c66f1c316dfe5703bb24cc17e355247"}}},"nbformat":4,"nbformat_minor":4}
